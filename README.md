# IPL_Data_Analysis_using_Spark
 

## 📌 Overview  

The project involves working with the IPL (Indian Premier League) dataset using Apache Spark. The objectives are to:

Upload data to Amazon S3: Store the IPL dataset on Amazon's Simple Storage Service (S3) for data storage.
Write Apache Spark code: Use Spark to read, transform, and process the data.
Apply business logic: Apply business logic to the data using Spark.
Perform SQL analytics: Use SQL to analyze the data and gain insights.
Create visualizations: Use the insights to create visualizations and understand the trends in the IPL dataset.
The project focuses on learning how to write Apache Spark code, specifically the "Pare Spark" code, and understanding the entire Spark ecosystem. 

The key components of the project include:
Apache Spark
Spark SQL
Spark Streaming
Machine Learning
Graphical Data Processing
The project aims to understand the architecture of Apache Spark, including the driver process, executor, and manager, and how they work together to process large-scale data in a distributed way.  

## 🚀 Technologies Used  
- **Apache Spark (PySpark)** – Distributed data processing  
- **Python** – Scripting and data manipulation  
- **Jupyter Notebook** – Interactive analysis  
- **Pandas & Matplotlib** – Data wrangling and visualization  

## 📂 Project Structure  
```
📦 IPL_DATA_ANALYSIS_SPARK
 ├── 📄 IPL_DATA_ANALYSIS_SPARK.ipynb  # Jupyter Notebook with the analysis
 ├── 📄 README.md                       # Project documentation
 ├── 📄 requirements.txt                 # Dependencies
```

## 🔹 Features  
✔️ Data ingestion & preprocessing using PySpark  
✔️ Exploratory Data Analysis (EDA)  
✔️ Performance analysis of teams & players  
✔️ Visualization of match trends and key statistics  

## 📊 Sample Insights  
- Top run-scorers and wicket-takers  
- Win-loss trends across seasons  
- Toss decisions & match outcomes correlation  

